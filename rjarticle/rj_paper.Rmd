---
title: "corVis: An R Package for Visualising Associations and Conditional Associations"
abstract: >
  Correlation matrix displays are important tools to explore multivariate datasets. These displays with other measures of association can summarize interesting patterns to an analyst and assist them in framing questions while performing exploratory data analysis. In this paper, we present new visualisation techniques to visualise association between all the variable pairs in a dataset in a single plot, which is something existing displays lack. Also, we propse new methods to visualise relationship among variable pairs using conditioning. We use different layouts like matrix or linear for our displays. We use seriation in our displays which helps in highlighting interesting patterns easily. The R package `corVis` provides an implementation.
draft: true
author:  
  
  - name: Amit Chinwan
    affiliation: Maynooth University
    address:
    - Hamilton Institute
    - Maynooth, Ireland
    email:  amit.chinwan.2019@mumail.ie
  - name: Catherine Hurley
    email: catherine.hurley@mu.ie
    affiliation: Maynooth University
    address:
    - Department of Mathematics and Statistics
    - Maynooth, Ireland
type: package
output: 
  rjtools::rjournal_web_article:
    self_contained: yes
    toc: no
bibliography: RJreferences.bib
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(corVis)
library(palmerpenguins)
library(ggplot2)
library(dplyr)
library(kableExtra)
library(magrittr)
```

# Section 1: Introduction

Correlation matrix display helps in visually exploring correlations among variables during Exploratory Data Analysis (EDA) of a multivariate dataset. Popularized by @friendly2002corrgrams as corrgram, these displays are produced by first calculating the correlation among the variables and then plotting these calculated values in a matrix display. With effective ordering techniques, these displays quickly highlight variables which are highly correlated and an analyst interested in building a predictive model could use these displays to flag and avoid multicollinearity.

The correlation displays are generally used with Pearson's correlation coefficient and are therefore limited to quantitative variables. An analyst can use one-hot encoding of the qualitative variables in order to use these displays but will need to deal with the high dimensions as a result of the encoding. In addition to the dimensionality problem, it is not easy to assess the overall correlation when using the one-hot encoding.  

<!-- The existing methods to quickly explore association among qualitative variables in a dataset include using proportions or counts with different graphical displays like boxplots or barplots. Using association measures for qualitative pairs similar to correlation for quantitative pairs will help in summarizing the relationship, which then can be displayed like the correlation displays.  -->

Tukey and Tukey [@tukey1985computer] introduced scagnostics which are diagnostic measures, quantifying density, shape, trend, and other features, of a scatterplot. Along with scagnostics, they proposed a scagnostics scatterplot matrix which is a visual display to explore and compare these measures for all the variable pairs in a dataset. By comparing multiple measures at once, the unusual variable pairs could be identified and looked at in more detail. In a similar manner, a display comparing association measures will help in finding interesting variable pairs. Many association measures have been proposed to summarize different types of relationships. The most commonly used measure is Pearson's correlation coefficient which captures any linear trend present between the variables. Other popular measures include Kendall's or Spearman's rank correlation coefficient which are non-parametric measures and looks for monotonic relationship. Distance correlation [@szekely2007measuring] is an important measure useful in exploring non-linear relationships. The information theory measure maximal information coefficient (MIC) [@reshef2011detecting] is capable of summarizing complex relationships. 

<!-- With effective displaying techniques, the multiple measures of association provide a comparison tool that assist an analyst to reveal structure present in the data. -->

Small multiples (or Trellis display) is a simple yet powerful approach to compare partitions of data and understand multidimensional datasets [@tufte1986thevisual]. The display is produced by splitting the data into groups by a conditioning variable and then plotting the data for each group. Such displays allow analysts to quickly infer about the impact of the conditioning variable. A similar idea applied to displays of association measures (correlation plot) will help uncover underlying patterns in the data. One such pattern is Simpson's paradox which can be detected by comparing Pearson's correlation for data at overall level versus individual levels of the conditioning variable.

In this paper, we propose extensions of the correlation plot and new visualizations which look at variables of mixed type, multiple association measures and conditional associations. These displays are implemented in the R package \CRANpkg{corVis}. The next section provides a review of existing packages which deal with correlation displays and a quick background on association measures and the packages used for calculating them. Then we describe our approach to calculate the association measures, followed by visualizations of associations and conditional associations. We conclude with a summary and future work.

# Section 2: Background

In this section we provide a brief review of  existing packages used for correlation displays and  association measure calculation. 

## Section 2.1: Literature Review on Correlation Displays



According to @hills1969looking, "the first and sometimes only impression gained by looking at a large correlation matrix is its largeness". To overcome this, @murdoch1996graphical proposed a  display for  large correlation matrices which uses a matrix layout of ellipses where the parameters of the ellipses  are  scaled to the correlation values. @friendly2002corrgrams  expanded on this idea by rendering correlation values as shaded squares, bars, ellipses, or circular ‘pac-man’ symbols. The variables in the matrix displays were optionally ordered using the angular ordering of the first two eigen vectors of the correlation matrix. The ordering places highly-correlated pairs of variables nearby, making it easier to quickly identify groups of variables with high mutual correlation.


Nowadays, there are many R  packages devoted to correlation visualisation. Table \@ref(tab:corrdisplay-packages) provides a summary, listing the displays offered, and whether these extend to factor variables or mixed numeric-factor pairs. 

The R package \CRANpkg{corrplot} [@corrplot2021] provides an implementation of the methods in @friendly2002corrgrams. 
 The package \CRANpkg{corrr} [@corrr2020] organises correlations as tidy data, so leveraging the data manipulation and visualisation tools of the \CRANpkg{tidyverse} [@tidyverse]. In addition to various matrix displays, the package offers network displays where line-thickness encodes correlation magnitude, with a filtering option to discard low-correlation edges.




The package \CRANpkg{corrgrapher} [@corrgrapher] uses a network plot for exploring correlations, where the nodes close to each other have high correlation magnitude, edge thickness encodes the absolute correlation value and edge color indicates the sign of correlation. The package also handles mixed type variables by using association measures obtained as transformations of $p$-values obtained from
Pearson's correlation test in the case of two numeric variables, Kruskal's test for numerical and factor variables, and a chi-squared test for two categorical variables. 

The package \CRANpkg{linkspotter} [@linkspotter] offers a variety of association measures (distance correlation, MIC, maximum normalized mutual information) in addition to correlation, where the measure used depends on whether the  variables are both numerical, categorical or mixed. The results are visualized in a network plot, which may be packaged into an interactive shiny application.


Our own package \CRANpkg{corVis} offers a variety of displays, and has new features not available elsewhere, in particular simultaneous display of multiple association measures, and association displays stratified by levels of a grouping variable. This will be described  in the following sections.


There have been other extensions to correlation displays which are useful when dealing with high dimensional datasets. 
@hills1969looking proposed a QQ plot of the $z$-transform of the entries of the correlation matrix to discover correlation coefficients too large to come from a normal distribution with mean zero. @buja2016visualization proposed Association Navigator which is an interactive visualization tool for large correlation matrices with upto 2000 variables.  The R package \CRANpkg{scorrplot} [@scorr] produces an interactive scatterplot for exploring pairwise correlations in a large dataset by projecting variables as points on a scatterplot with respect to some user-selected variables of interest, driven by a geometric interpretation of correlation and encoding the correlation as vertical gridlines in the plot. The package allows user to update variable of interest which creates tour of the correlation space between different projections of the data. 



The R package \CRANpkg{correlationfunnel} offers a novel display which assists in feature selection in a setting with a single response and many predictor variables. All numeric variables including the response are binned. All (now categorical) variables in the resulting dataset are one-hot encoded and Pearson's correlation calculated with the response categories. The correlations are visualised in a dot-plot display, where predictors are ordered by maximum correlation magnitude. Correlations between one-hot encoded variables are challenging to interpret, especially as the number of levels increase.  In corVis we offer a similar dot-plot display, but showing multiple correlation or association measures, or alternatively measures stratified by a grouping variable.


```{r corrdisplay-packages,warning=FALSE,message=FALSE,echo=FALSE }
library(kableExtra)

Package <- c("corrplot","corrr","corrgrapher","linkspotter",  "correlation","corVis")

Display <- c("heatmap","heatmap/network","network","network","heatmap/network","heatmap/matrix/linear")


MixedVariables <- c(" "," "," ","Yes"," ","Yes")



df <- data.frame(Package=Package,
                 Display=Display,
                 MixedVariables=MixedVariables)

kableExtra::kbl(df, booktabs = T, caption = "List of the R packages dealing with correlation or correlation displays with information on whether the plots display multiple measures, conditional display of measures and mixed variables in a single plot")
#print(table_1)
#df %>%
  #kbl() %>%
  #kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```




## Section 2.2: Literature Review on Association Measures

An association measure is defined as a numerical summary quantifying the relationship between two or more variables. The measure is called symmetric if its value is invariant to the choice of independent or dependent variable during the calculation. For example, Pearson's correlation coefficient summarizes the strength and direction in the range $[-1,1]$ of the linear relationship present between two numeric variables and is symmetric. Kendall's or Spearman's rank correlation coefficient are other popular measures which assess monotonic relationship in interval $[-1,1]$ among two numeric variables and are symmetric measures. 

<!-- As these measures are limited to linear or monotonic relationships, there's a need to use association measures which are able to capture complex relationships.  -->

Pearson's correlation is the most popular association measure because of its easier calculation and interpretability but its limitations such as influence of outliers on its value and measuring only linear dependencies makes it a less useful measure of association overall. The recent measures such as distance correlation [@szekely2007measuring] and MIC [@reshef2011detecting] overcome these limitations and are more suitable for datasets with both linear and non-linear patterns.

```{r motivation-patterns, fig.width=5, fig.height=4, fig.align='center', fig.cap = "Multiple association measures for simulated linear and non-linear pattern. The first row of the plot shows a linear pattern, the value of Pearson's correlation, distance correlation and MIC. The second row of the plot shows a non-linear pattern along with the values for association measures. All three association measures show a high value for the linear relationship and hence are useful for linear patterns. For the non-linear pattern, distance correlation and MIC are more suitable measures than Pearson's correlation."}

library(ggplot2)
library(mvtnorm)
library(gridExtra)

MvNormal <- function(n = 200, cor = 1) {
  for (i in cor) {
    sd = matrix(c(1, i, i, 1), ncol = 2)
    x = MASS::mvrnorm(n, c(0, 0), sd, empirical=T)
    #print(plot_fun(x))
    return(x)
  }
}
# positive linear pattern
xy <- MvNormal(cor=0.9)
xlp <- xy[,1]; ylp <- xy[,2]

data_linear <- data.frame(x = xlp, y = ylp)

p1_linear <- ggplot(data = data_linear) + geom_point(aes(x=x, y=y),size=0.5) +
  coord_fixed() + theme_void()

p2_linear <- ggplot(data=data_linear) + 
  theme_void() + 
  geom_text(aes(0,0, label= paste0( "r = ", round(cor(data_linear[,"x"], data_linear[,"y"]), 1) ))) +
  coord_fixed()

p3_linear <- ggplot(data=data_linear) + 
  theme_void() + 
  geom_text(aes(0,0, label= paste0( "dcor = ", round(sqrt(energy::dcor2d(data_linear[,"x"], data_linear[,"y"])), 1)))) +
  coord_fixed()

p4_linear <-  ggplot(data=data_linear) + 
  theme_void() +
  geom_text(aes(0,0, label= paste0( "MIC = ", round(minerva::mine(data_linear[,"x"], data_linear[,"y"])[[1]], 1)))) +
  coord_fixed()


# quadratic pattern
set.seed(123)
x = runif(200, -1, 1)

yq = 2*x^2 + runif(200, 0, 1)

data_quad <- data.frame(x = x, y = yq)

p1_quad <- ggplot(data = data_quad) + geom_point(aes(x=x, y=y),size=0.5) + coord_fixed() + theme_void()

p2_quad <- ggplot(data=data_quad) + 
  theme_void() + 
  geom_text(aes(0,0, label= paste0( "r = ", round(cor(data_quad[,"x"], data_quad[,"y"]), 1) ))) +
  coord_fixed()

p3_quad <- ggplot(data=data_quad) + 
  theme_void() + 
  geom_text(aes(0,0, label= paste0( "dcor = ", round(sqrt(energy::dcor2d(data_quad[,"x"], data_quad[,"y"])), 1)))) +
  coord_fixed()

p4_quad <-  ggplot(data=data_quad) + 
  theme_void() +
  geom_text(aes(0,0, label= paste0( "MIC = ", round(minerva::mine(data_quad[,"x"], data_quad[,"y"])[[1]], 1))))+
  coord_fixed()




library(gridExtra)
grid.arrange(p1_linear,p2_linear,p3_linear,p4_linear,
             p1_quad,p2_quad,p3_quad,p4_quad, nrow=2)



```

Figure \@ref(fig:motivation-patterns) shows a plot of simulated linear and non-linear patterns. The first row shows a linear relationship along with the value for measures such as Pearson's correlation, distance correlation and maximal information coefficient respectively for the pattern. In a similar manner, the second row shows a quadratic relationship and its values for  Pearson's correlation, distance correlation and maximal information coefficient respectively.   
It is clearly evident from Figure \@ref(fig:motivation-patterns) that all the three measures summarizes the pattern with linear relationship quite well. For the non-linear pattern, distance correlation and MIC are better in detecting underlying relationship than Pearson's correlation. This suggests that association measures such as distance correlation, MIC and other measures should be used along with Pearson's correlation for exploring relationships among variables in the datasets where there is no prior knowledge about the possible patterns in the data.

The distance correlation coefficient [@szekely2007measuring] is an association measure which looks for any relationship among two numeric variables using the distances between observations of these variables and summarizes the relationship in $[0,1]$. The distance correlation is $0$ only when the variables are independent and is a symmetric measure. 

The maximal information coefficient (MIC) [@reshef2011detecting] is an information theory measure which uses mutual information among the two variables for its calculation. The main idea is to find a grid out of possible grids on a scatterplot of two numeric variables, in order to discretize the variables, which maximises the mutual information for the two variables. A normalisation technique is used to make the mutual information from different grids comparable. Referred as 'a correlation of 21st century' [@speed2011correlation], MIC is capable of summarizing different types of relationships, not just linear or monotonous, between numeric variables and is in range $[0,1]$. @reshef2011detecting used MIC and other related statistics to explore pairwise relationships in large data sets such as major-league baseball, gene expression, global health, and the human gut microbiota. 

Both distance correlation and MIC have advantages of detecting non-linear and complex relationship but these measures aren't perfect yet. @commentSimonTibshirani showed that distance correlation has more statistical power than MIC. Also, distance correlation is not an approximation when compared to MIC. On the other hand, distance correlation computation is slower as compared to the conventional association measures such as Pearson's correlation for datasets with high number of cases.

In addition to association measures for numeric variables, association measures for ordinal, nominal and mixed variable pairs are useful in exploring a multivariate dataset. We now give an overview of available association measures for other variable types.

@agresti2010analysis provides an overview of the association measures which are used for exploring association between ordinal variables. Kendall's tau-b [@kendall1945treatment] is an association measure useful in summarizing the relationship in range $[-1,1]$ between two ordinal variables. It is a relatively stable measure than Goodman and Kruskal's gamma with respect to the changes in categories of any variable i.e. if two categories are merged to make a single category. The polychoric correlation [@olsson1979maximum] measures the correlation between two ordinal variables  by assuming two normally distributed latent variables for a contingency table of two ordinal variables and summarizes the association in $[-1,1]$.

<!-- For a pair of nominal variables -->
The association measures for the case of nominal pair of variables should be invariant to the order in which the categories appear. Pearson's contingency coefficient uses the ${\chi}^2$ value from the Pearson's ${\chi}^2$ test for independence and is a useful measure to summarize the association in $[0,1]$ between two nominal variables.  Another measure for nominal variable pair is the Uncertainty coefficient [@theil1970estimation] measuring the proportion of uncertainty in one variable which is explained by the other variable. The uncertainty coefficient measure is in the range $[0,1]$ and is not symmetric.

<!-- For a pair of mixed variables -->

<!-- The canonical correlation is a measure useful in exploring association among mixed variables. The goal of the canonical correlation analysis is to maximize the association between the low-dimensional projections of two sets of variables [@hardle2019applied]. Each of these measures are are consistent with respect to the order of the categories of the nominal variable. -->




# Section 3: Introducing corVis


\CRANpkg{corVis} is an R package which calculates measures of association for every variable pair in a dataset and provides visualizations for displaying associations. Most of the existing correlation displays are limited to numeric pairs of variables. This package extends these displays to every variable pair. The main goal of our work is to propose displays for multiple association measures and conditional associations display which are useful for uncovering interesting patterns in the data. This will help in identifying variable pairs which shows a type of relationship or pattern in a dataset with large number of variables.


```{r motivation2, fig.width=5, fig.height=4, fig.align='center', fig.cap = "An example plot showing importance of conditional displays"}
# 
# a <- data.frame( x = rnorm(100), y = rnorm(100)) %>% mutate(y = y-x/2)
# b <- a %>% mutate(x=x+2) %>% mutate(y=y+2)
# c <- a %>% mutate(x=x+4) %>% mutate(y=y+4)
# data <- do.call(rbind, list(a,b,c))
# data <- data %>% mutate(group=rep(c("A", "B", "C"), each=100))
# 
# p1 <- ggplot(data=data) + geom_point(aes(x=x,y=y))
# p2 <- ggplot(data=data) + geom_point(aes(x=x,y=y, color=group))
# 
# gridExtra::grid.arrange(p1,p2,ncol=2)
```

<!-- Consider Figure \@ref(fig:motivation2) for the motivation behind conditional association displays. The plot on the left shows a positive linear association between `y` and `x` and has a positive Pearson's correlation of value 0.603. The plot on the right shows the disaggregated data by the `group` variable and it is clearly evident that for each group there is a negative linear relationship between `y` and `x`. This is an example of Simpson's paradox and is one of the patterns which are discoverable when conditional association displays are used. -->

While designing these displays we consider matrix and linear layouts. A matrix layout reduces the effort in looking up for variable pairs corresponding to a cell or panel, and different measures may be displayed on the upper and lower triangle of the matrix. On the other hand, the filtering of variable pairs, for example pairs having measure value greater than a threshold, is easier with linear layouts in comparison to matrix layouts.

Table \@ref(tab:function-corVis) provides a list of the functions available in the package. The functions `calc_assoc` and `calc_assoc_all` are responsible for calculating association measures which are used as input for the `plot_assoc_matrix` and `plot_assoc_linear` functions. The functions `plot_assoc_matrix` and `plot_assoc_linear ` produces association display, multiple association measures display and conditional association display, in a matrix and linear layout respectively. We provide detailed examples on calculation and visualisation of association and conditional association in next sections.

<!-- which are useful for calculating association measures among variable pairs and visualising these associations using novel displays. Section 4 provides a detailed description on functions used for calcuating association measures in the package. Section 5 illustrates the use of visualising functions in table \@ref(tab:function-corVis) for displaying pairwise association and conditional association. -->


```{r function-corVis,warning=FALSE,message=FALSE,echo=FALSE }
library(kableExtra)

Function <- c("calc_assoc","calc_assoc_all","plot_assoc_matrix","plot_assoc_linear",
              "show_assoc")

Usage <- c("Calculation","Calculation","Visualization","Visualization",
           "Visualization")

#Usage <- c(rep("Calculation",5),rep("Visualization",3),rep("Visualization",5),rep("Visualization",4),rep("Visualization",5))

Description <- c("Calculates association measures",
                 
                 "Calculates all the association measures available in package",
                 
                 "Visualize assocition and conditional association in matrix plot",
                 
                 "Visualize assocition and conditional association in linear plot",
                 
                 "Association (or conditional) plot for a pair of variables")


df <- data.frame(Function=Function,
                 Usage=Usage,
                 Description=Description)

kableExtra::kbl(df,booktabs = T, caption = "List of functions in corVis package") %>%
  kableExtra::column_spec(1, bold=T)


  #kableExtra::collapse_rows(columns = 1:2)

#print(table_1)
#df %>%
  #kbl() %>%
  #kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```


# Section 4: corVis: Calculating Association

This section describes the calculation of association measures in our package \CRANpkg{corVis}. The package  provides a standard interface for calculating a collection of various measures of association which quantifies the relationship between two variables. The association measures available in the package are not limited to numeric variables and are used with nominal, ordinal and mixed variable pairs as well. The package also provides a functionality for handling missing value or `NA` while calculating the association measures. 

Table \@ref(tab:association-measures) lists different functions provided in the package to calculate varoius measures of association. The `Function` column represents `tbl_*` functions which are used to calculate a single association measure. The `typeX` and `typeY` columns provide the information on types of variables which can be used with the corresponding functions. The `X` or `Y` variable is one of the numeric, nominal or ordinal type. The `from` column corresponds to the external package functions used to calculate the association measures by `tbl_*` functions. The `symmetric` column represents if the measure is symmetric i.e. if its value doesn't change by the choice of independent or dependent variable during its calculation. The last column provides the range of values for these measures. The function `tbl_easy` calculates association measures available in the R package \CRANpkg{correlation} and is suitable for different variable types. 

The functions in Table \@ref(tab:association-measures) such as `tbl_ace`, `tbl_cancor` and `tbl_nmi` which calculates maximal correlation coefficient, canonical correlationa and normailzed mutual information respectively, have been implemented in \CRANpkg{corVis}.


For numeric pairs of variables, the package provides a range of association measures. The popular correlation coefficients like Pearson's, Spearman's or Kendall's are calculated using `tbl_cor` function. The measures such as distance correlation or MIC are calculated using `tbl_dcor` or `tbl_mine` respectively. The association measures  available in the package for the ordinal pairs of variables are polychoric correlation and Kendall's coefficients which are calculated using `tbl_polycor` or `tbl_tau` respectively. For nominal pairs of variables, the functions like `tbl_gkTau`, `tbl_gkGamma`, `tbl_uncertainty`, `tbl_chi`, `tbl_cancor` are used for exploring association among the variables. 


<!-- These measures are consistent with respect to the order of the levels of nominal variable which some of the existing measures lack. -->

The function `tbl_cancor` calculates a measure of association based on canonical correlations for mixed pairs of variables. Nominal variables are converted into sets of dummy variables, which are then assigned score to find the maximal correlation. For two numeric variables this measure is identical to absolute correlation, for two factors the correlation is identical to that obtained from correspondence analysis.

The functions listed in Table \@ref(tab:association-measures) for calculating association measures provide a functionality for handling missing value or `NA` in the dataset. Each of these functions either have a `handle.na` argument or automatically uses pairwise complete observations (depending on the package used for calculation) for taking care of missing values present in the data. 

```{r association-measures,echo=FALSE}

assocMethods <- tribble(
  ~Function, ~X, ~Y,  ~from, ~symmetric, ~range,
  "tbl_cor", "numerical", "numerical",  "stats::cor", "Y", "[-1,1]",
  "tbl_dcor", "numerical", "numerical",  "energy::dcor2d", "Y", "[0,1]",
  "tbl_mine", "numerical", "numerical", "minerva::mine","Y", "[0,1]",
  "tbl_ace", "numerical", "numerical", "corVis","Y", "[0,1]",
  "tbl_polycor", "ordinal", "ordinal", "polycor::polychor", "Y", "[-1,1]",
  "tbl_tau", "ordinal", "ordinal", "DescTools::KendalTauA,B,C,W", "Y", "[-1,1]",
  "tbl_gkGamma", "ordinal", "ordinal", "DescTools::GoodmanKruskalGamma", "Y", "[-1,1]",
  "tbl_gkTau", "nominal", "nominal", "DescTools::GoodmanKruskalTau", "N", "[0,1]",
  #"tbl_gkLambda", "nominal", "nominal", "DescTools::GoodmanKruskalTau", TRUE, "[0,1]",
  "tbl_uncertainty", "nominal", "nominal", "DescTools::UncertCoef", "Y", "[0,1]",
  "tbl_chi", "nominal", "nominal", "DescTools::ContCoef", "Y", "[0,1]",
  "tbl_cancor", "nominal/numerical", "nominal/numerical", "corVis", "Y", "[0,1]",
  "tbl_nmi", "nominal", "nominal", "corVis", "Y", "[0,1]",
  "tbl_easy", "nominal/numerical", "nominal/numerical", "correlation::correlation", "Y", "[-1,1]")

kableExtra::kbl(assocMethods,booktabs = T,caption = "List of the functions available in the package for calculating different association measures along with the packages used for calculation.") %>% kableExtra::kable_styling(latex_options = "scale_down")
#kableExtra::kable_styling(kable_input,latex_options = "striped")
#knitr::kable(assocMethods)
```

## Calculating association for a single type of variable pairs

We have a function which creates a tibble structure for the variable pairs in a dataset along with calculated association measure. The package contains various functions (shown in Table \@ref(tab:association-measures)) for different association measures in the form `tbl_*` to calculate them. For example, in order to calculate distance correlation for numeric pair of variables in a dataset, the function `tbl_dcor` is used.

```{r,echo=TRUE}


distance <- tbl_dcor(iris)
distance
```


In the tibble output for the functions mentioned in Table \@ref(tab:association-measures) `x` and `y` represents a pair of variables. The `measure` variable represents the calculated value for association measure. And the `measure_type` variable represents the association measure calculated for `x` and `y` pair.

## Calculating association measures for whole dataset

`calc_assoc` is used to calculate association measures for all variable pairs in a dataset at once in a tibble structure. The variable pairs in the output are unique pairs in the dataset where `x` $\neq$ `y`. Because of the tidy structure of the output, the data manipulation and visualisation tools of \CRANpkg{tidyverse} [@tidyverse] are applicable and are useful for further exploration of pairwise associations. In addition to tibble structure, the output also has `pairwise` and `data.frame` class which are important class attributes for producing visual summaries in this package.

The function `calc_assoc` has a `types` argument which is a tibble of the `tbl_*` functions for different types of variable pairs. The default tibble is `default_assoc()` which includes `tbl_cor` if both the variables are numeric and calculates Pearson's correlation , `tbl_gkGamma` if both the variables are ordinal and calculates Goodman and Kruskal's gamma , `tbl_cancor` if one is factor and other is numeric and calculates canonical correlation, and canonical correlation for the rest of the variable pairs.

```{r,echo=TRUE}
default_measures <- default_assoc()
default_measures

iris_assoc <- calc_assoc(d = iris,
                         types = default_measures)
iris_assoc
class(iris_assoc)
```


The default tibble of measures is updated using the `update_assoc` function which has arguments for updating the `tbl_*` functions to calculate association measures depending on the type variable pair in the dataset and a method for `tbl_*` functions which calculates more than one measure. The `update_assoc` function has an argument `default` which has the `default_assoc()` tibble as its default value and is useful when `tbl_*` functions need to be updated for a few types of variable pairs. 


```{r,echo=TRUE}
updated_assoc <- update_assoc(default_measures,
                              num_pair = "tbl_cor",
                              num_pair_argList = "spearman",
                              mixed_pair = "tbl_cancor",
                              other_pair = "tbl_nmi")
updated_assoc

```

```{r,echo=TRUE}

updated_iris_assoc <- calc_assoc(d = df, 
                                 types = updated_assoc)
updated_iris_assoc

```

`calc_assoc` also has a `handle.na` argument for handling the `NA` or missing values which is fed into the `tbl_*` functions used with the `types` argument for different types of variable pairs. The default value is set to `TRUE` for using pairwise complete observations for calculating a measure of association between two variables.



## Calculating multiple association measures


The multiple association measures are calculated using `calc_assoc_all` function in the package. The function takes a dataset and a list of measures as input and outputs a tibble structure with multiple measures of association for every variable pair. This output serves as input to the multiple association measures plot function for comparison of measures for variable pairs.

```{r}
iris_assoc_multi <- calc_assoc_all(d = iris,
                                   measures = c("pearson",
                                                "dcor",
                                                "cancor"))
iris_assoc_multi
```



## Calculating conditional association

`calc_assoc` is also used to calculate association measures for all the variable pairs at different levels of a categorical variable. This helps in exploring the conditional associations and find out the differences between the groups of the conditioning variable. The function has a `by` argument which is used as the grouping variable and needs to be categorical.

```{r,echo=TRUE}
iris_assoc_by <- calc_assoc(d = iris,
                            by = "Species")
iris_assoc_by
```

<!-- The `calc_assoc_by` function also has a `types` argument which can be updated similarly to `calc_assoc`.  -->

<!-- ```{r,echo=TRUE} -->
<!-- updated_assoc <- update_assoc(num_pair = "tbl_cor", -->
<!--                               num_pair_argList = "spearman", -->
<!--                               mixed_pair = "tbl_cancor", -->
<!--                               other_pair = "tbl_nmi") -->
<!-- updated_penguin_assoc_by <- calc_assoc_by(df,by = "sex", types = updated_assoc) -->
<!-- head(updated_penguin_assoc_by) -->
<!-- ``` -->

By default, the function `calc_assoc` calculates the association measures for all the variable pairs at different levels of the grouping variable and the pairwise association measures for the ungrouped data (`overall`) when used with the `by` argument. This behavior can be changed by setting `include.overall` argument to `FALSE`.

```{r,echo=TRUE}
iris_assoc_by <- calc_assoc(d = iris,
                            by = "Species",
                            include.overall = FALSE)
iris_assoc_by
```

The tibble output in the conditional setting has a similar structure as `calc_assoc` used with no `by` argument. When used with the `by` argument, an additional `by` column representing the levels of the categorical variable is added to the tibble output. The `x` and `y` variables in the output are repeated for every level of `by` variable. In order to have multiple `by` variables, the function `calc_assoc` is used multiple times with a different `by` variable each time and then the multiple outputs are binded row wise. 


# Section 5: corVis: Visualising Association

This section provides a detailed description of the novel visualisation techniques proposed in the package \CRANpkg{corVis}. These methods display association and conditional association for every variable pair in a dataset in a single plot and show multiple bivariate measures of association simultaneously. The package includes functions such as `plot_assoc_matrix` and `plot_assoc_linear` to produce these displays in matrix and linear layout respectively. In addition, the package also provides a function `show_assoc` to display a scatterplot for a numeric variable pair input, a box plot for mixed variable pair input and bar plot for other variable pair input.

We use two datasets to provide illustrative examples. The first dataset is `de_elect` (German Election Data from 2002 and 2005) from \CRANpkg{zenplots} package which includes numeric variables only. The German Election dataset provides the information on election results for two German elections held in 2002 and 2005. The dataset includes $299$ constituencies and $68$ variables providing information on these constituencies. For our analysis, we use a subset of variables from German election dataset which are described in Table \@ref(tab:germanelection). The poor economic performance of the country was one of the dominant issues during 2002 German election. To analyse the same, we use variables including vote proportion for three major parties in 2002 election, population percentages for different age groups, percentage of employees in different sectors subjected to social insurance contribution and percentage unemployment. 

```{r germanelection,warning=FALSE,message=FALSE,echo=FALSE }
library(kableExtra)
library(zenplots)
data("de_elect")

selected_vars <- c("SPD.02",
                   "CDU.CSU.02",
                   "Gruene.02", 
                   "Pop.18.25", 
                   "Pop.25.35",
                   "Pop.35.60",
                   "Industry",
                   "CTT", 
                   "Unemployment.03")

german_election <- de_elect[selected_vars]

Variable <- names(german_election)

Description <- c("Proportion of votes for SPD in 2002",
                 "Proportion of votes for CDU/CSU in 2002",
                 "Proportion of votes for Gruene in 2002",
                 "population between 18 and 25 years old 2002-12-31 (in percent)",
                 "population between 25 and 35 years old 2002-12-31 (in percent)",
                 "population between 35 and 60 years old 2002-12-31 (in percent)",
                 "industry employees subject to social insurance contribution (in percent)",
                 "commerce, transportation and telecommunication employees subject to social insurance contribution (in percent)",
                 "unemployment 2003-12-31 (in percent)")

#VariableType <- c("numerical","numerical","numerical","numerical","numerical","numerical","numerical","numerical","numerical","numerical")

df <- data.frame(Variable=Variable,
                 Description=Description
                 #VariableType=VariableType
                 )

kableExtra::kbl(df, booktabs = T, caption = "Variable description of a subset of the German election result dataset from 2002 and 2005.") |>
  kableExtra::kable_styling(latex_options = "scale_down")
#print(table_1)
#df %>%
  #kbl() %>%
  #kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

`cdc` (Behavioral survey data) is the second dataset from @cdc which includes numeric, nominal and ordered variables. The dataset is a random sample of 20,000 people from Behavioral Risk Factor Surveillance System (BRFSS) survey, which is an annual telephonic survey of 350,000 people, in United States collected by the Centers for Disease Control and Prevention (CDC) conducted in 2000. The respondents of the survey are asked questions related to their diet, weekly physical activity and even their level of health coverage. The goal of the survey is to identify risk factors in adult population and report the health trends. The dataset used here has only 9 questions or variables as compared to the original dataset which includes more than 200 variables.Table \@ref(tab:cdcdata) provides a brief description of the variables in `cdc` dataset along with the variable type. The variables `genhlth`, `exerany`, `smoke100` and `age`  in the dataset were converted to ordinal factors as they had a natural ordering. `hlthplan` and `gender` were considered as nominal factors for the analysis. During the association analysis, we found some individuals with very high values for `height`, `weight` and `wtdesire`, and filtered out these cases for further analysis.

```{r cdcdata,warning=FALSE,message=FALSE,echo=FALSE }
library(kableExtra)
cdcdata <- read.csv("../data/cdc.csv")

cdcdata$genhlth <- as.ordered(factor(cdcdata$genhlth,levels = c("poor", "fair", "good", "very good", "excellent")))
levels(cdcdata$genhlth)[levels(cdcdata$genhlth)=="very good"] <- "v.good"
cdcdata$exerany <- as.ordered(factor(cdcdata$exerany,levels = c(0,1)))
cdcdata$hlthplan <- factor(cdcdata$hlthplan)
cdcdata$smoke100 <- as.ordered(factor(cdcdata$smoke100, levels = c(0,1)))
cdcdata$gender <- factor(cdcdata$gender)
cdcdata$age <- cut(cdcdata$age, 
                   breaks=c(18,25,35,60,99), 
                   include.lowest = T, 
                   ordered_result = T)
cdcdata <- dplyr::filter(cdcdata, !height >= 90)
cdcdata <- dplyr::filter(cdcdata, !weight >= 450)
cdcdata <- dplyr::filter(cdcdata, !wtdesire >= 450)

variable <- names(cdcdata)

description <- c("General health, with categories excellent, very good, good, fair, and poor",
                 "Respondent exercised in the past month with category 0 and 1",
                 "Respondent has some form of health coverage",
                 "Respondent has smoked at least 100 cigarettes in their entire life with category 0 and 1",
                 "Respondent's height in inches",
                 "Respondent's weight in pounds",
                 "Respondent's desired weight",
                 "Respondent's age in categories [18,25], (25,35], (35,60], (60,99]",
                 "Respondent's gender")

variable_type <- c("ordinal","ordinal","nominal","ordinal","numerical","numerical","numerical","ordinal","nominal")

df <- data.frame(Variable=variable,
                 Description=description,
                 VariableType=variable_type
                 )

kableExtra::kbl(df, booktabs = T, caption = "Variable description of the CDC dataset") |>
  kableExtra::kable_styling(latex_options = "scale_down")
#print(table_1)
#df %>%
  #kbl() %>%
  #kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```


## Association plots

For association analysis, we start with calculating the default association measures for the `cdc` data using `calc_assoc` and then this result is plotted using `plot_assoc_matrix` in a matrix layout in Figure \@ref(fig:assoc-matrix-cdcdata). 
```{r assoc-matrix-cdcdata,fig.width=5, fig.height=5, fig.align='center', fig.cap="Association matrix display for cdc data showing Pearson's correlation for the numeric variable pairs, Goodman Kruskal's gamma measure for ordered variable pairs, canonical correlation for mixed variable pairs, nominal variable pairs and other variable pairs. The off diagonal cells show the measure value for a variable pair using a square glyph. The color of every square is mapped with the measure value for the variable pair and the area of the square is mapped by absolute measure value for the corresponding variable pair. The plot shows a strong association between desired weight and gender of the indvividuals. Also, there is an negative association between the general health and the age of the individuals suggesting the health of individuals deteriorating with age.",echo=TRUE}

assoc_cdc <- calc_assoc(d = cdcdata)
plot_assoc_matrix(lassoc = assoc_cdc)
```

The diagonal cells in Figure \@ref(fig:assoc-matrix-cdcdata) represent the variables present in the data. Every off diagonal cell contains a glyph, square in this plot, which is filled with a divergent color scale representing the value of corresponding association measure for a variable pair. The `glyph` argument can be either `square` or `circle`. The area of the square is mapped to absolute value of the association measure which quickly highlights the associated pairs of variables. We also offer ordering of the variables in this display so that highly-associated variables are arranged closer to each other and the task of detecting patterns or relations becomes easier. The argument `var_order` is used for the variables in the matrix display. The function uses average linkage hierarchical clustering of the association matrix of the variables for ordering the variables, which clusters the highly associated variables together and arranges them nearby.

Figure \@ref(fig:assoc-matrix-cdcdata) shows a high positive Pearson's correlation for (`wtdesire`, `height`) which suggests that taller individuals have higher desired weights. The plot also shows a negative Goodman Kruskal's gamma measure for the ordered variable pairs (`genhlth`, `age`) and (`genhlth`, `smoke100`) indicating that the health of individuals deteriorates as they age and with more smoking. The positive association for (`smoke100`, `age`) implies that older people tend to smoke more. Also, it is evident from the plot that individuals who exercise often are more healthier, shown by the variable pair (`exerany`, `genhlth`).  

In order to explore these variable pairs in more detail, the function `show_assoc` is used to plot a scatterplot and a mosaic plot for numeric and ordinal pairs respectively in Figure \@ref(fig:int-pairs-cdcdata).

```{r int-pairs-cdcdata, fig.show="hold", out.width="50%", fig.cap = "Scatterplot and mosaic plots for numeric variable pair (wtdesire, height) and ordinal variable pairs (genhlth, age), (genhlth,smoke100) and (smoke100, age) showing association between these pair of variables.", echo=TRUE}


show_assoc(d = cdcdata, 
           x = "wtdesire", 
           y = "height")

show_assoc(d = cdcdata, 
           x = "age", 
           y = "genhlth")


show_assoc(d = cdcdata, 
           x = "genhlth", 
           y = "smoke100")


show_assoc(d = cdcdata, 
           x = "smoke100", 
           y = "age")
```


## Multiple Association Measures Plot

<!-- We also calculate multiple association measures for all the variable pairs in the dataset and compare them. This helps in identifying pairs of variables with a high difference among different measures or any unusual variable pairs which should be investigated further in more detail.  -->

The multiple association measures plot compares the multiple association measures for all the variable pairs in a dataset. This display is useful in detecting variable pairs with high difference among the measures which then can be explored further in more detail. 

```{r compare-linear-heatmap,fig.width=4.5, fig.height=6.5, fig.align='center',fig.cap="Multiple association measures plot in a linear layout for a subset of German election data. The plot has variable pairs on the Y-axis and association measures on the X-axis. The color intensity of each cell is proportional to the absolute value of association measure. The variable pairs on Y-axis are ordered by the maximum difference between the absolute value of association measures. The plot shows the highest difference for variable pair V.FDP.02 and V.Linke.02 which can be explored further to understand the underlying reasons for this difference.",echo=TRUE}


assoc_german_all <- calc_assoc_all(d = german_election,
                                   measures = c("ace",
                                                "pearson",
                                                "spearman",
                                                "kendall",
                                                "dcor",
                                                "spearman",
                                                "mic"))

plot_assoc_linear(assoc = assoc_german_all, 
                  plot_type = "heatmap",
                  limits = c(0,1),
                  var_order = "max_diff")

```

Figure \@ref(fig:compare-linear-heatmap) shows a multiple association measures plot in linear layout for German election dataset. The plot compares the absolute values of association measures such as `ace`, `dcor`, `kendall`, `mic`, `pearson` and `spearman` for every variable pair in the dataset. Each cell of the plot corresponds to a variable pair and an association measure, and color intensity of each cell corresponds to the absolute value of association measure. The variable pairs in the plot are ordered by the maximum difference between the absolute value of these measures. The plot shows the variable pair (`Unemployment.03`,`CTT`) with highest difference between the association measures. The low value for Pearson's correlation and Kendall's correlation suggest no trend but measures such as ace, distance correlation, MIC and Spearman's correlation indicates that a relationship might exist among the variables. Another interesting variable pair evident from the plot is (`Pop.35.60`, `Gruene.02`) for which the three popular measures like Pearson's, Kendall's and Spearman's correlation coefficient are almost zero but measures such as ace, distance correlation and MIC suggest presence of a pattern. 

We use `show_assoc` to explore the relationship for the interesting variable pairs in Figure \@ref(fig:int-pairs-multiple-germanelection).  It is evident from the plots that the variable pairs (`Unemployment.03`,`CTT`) and (`Pop.35.60`, `Gruene.02`) show a non-linear trend for which measures such as Pearson's correlation, Kendall's correlation and Spearman's correlation might not be suitable. 

```{r int-pairs-multiple-germanelection, fig.show="hold", out.width="50%", fig.cap = "Scatterplot for variable pairs (from left to right) (Unemployment.03 and CTT) and (`Pop.35.60`, `Gruene.02`) showing relationships between these pair of variables.",echo=TRUE}

show_assoc(d = german_election,
           x = "Unemployment.03",
           y = "CTT")

show_assoc(d = german_election,
           x = "Gruene.02",
           y = "Pop.35.60")
```



<!-- The function `plot_assoc_linear` is used to display Figure \@ref(fig:compare-linear-heatmap). The function takes tibble of association measures calculated by `calc_assoc_all` as input and outputs a multiple association measures plot in linear layout. `group_var` argument is set to `measure_type` for a multiple measures plot. A maximum difference ordering is used for the plot by setting the `var_order` argument to `max_diff`. The `plot_type` argument is used for the type of plot for plotting the association measures. It is set to `heatmap` for rendering the color intensity to measure value or `dotplot` when points are used to represent the measure value. The `limits` argument is set to `c(0,1)` for multiple measures plot. -->


## Conditional Association Plot

The conditional association plot is produced by splitting the data by a partitioning variable and calculating association for the variable pairs at each level of partitioning variable using `calc_assoc` function with conditioning variable as the `by` argument. The calculated association measures are then displayed using bars in a matrix plot. The height and color of the bars are coded with the value of association measure and the level of the partitioning variable respectively. These displays are efficient for discovering variable pair with high differences among the levels of partitioning variable in the data.


```{r cond-assoc,fig.width=5, fig.height=5, fig.align='center', fig.cap="Conditional Association plot for cdc data showing Pearson's correlation for numeric pairs, Goodman and Kruskal's gamma for ordinal pair, canonical correlation for nominal or mixed pairs. The bars in each cell represent the value for asssociation measure colored by the conditioning variable genhlth The dotted line in each cell represents overall value of the association measure. The plot shows evident difference in measure value for pair (smoke100, age) and (weight, gender) for participants with different levels of health in the data.",echo=TRUE}

cond_assoc_cdc <- calc_assoc(d = cdcdata, 
                             by = "genhlth")
plot_assoc_matrix(lassoc = cond_assoc_cdc)
```

Figure \@ref(fig:cond-assoc) shows a conditional association plot for the cdc data. Each cell corresponding to a variable pair shows two bars which correspond to the association measure (Pearson's correlation for numeric pairs, Goodman and Kruskal's gamma for ordinal pair, canonical correlation for nominal or mixed pairs) calculated at the levels of conditioning variable `genhlth`. The dotted line represents the overall association measure. The plot indicates that there is an evident difference in the Goodman and Kruskal's gamma for the variable pair (`smoke100`, `age`) for different levels of health, compared with each other and overall value. Also, the canonical correlation for variable pair (`weight`, `gender`) for individuals feeling poor or fair health is low compared to the overall value. We explore these variable pairs in more detail using `show_assoc`.


Figure \@ref(fig:int-pairs-conditional-cdc) shows a barplot for the variable pair (`smoke100`, `age`) and a boxplot for variable pair (`weight`, `gender`) faceted by the conditioning variable `genhlth`. The faceted barplot shows that individuals who are old with smoking habits suffer with poor health more (almost twice) compared to individuals who are old and don't smoke. Interstingly, the faceted boxplot shows that healthier females have low weight compared to the females who don't feel healthy. On the other hand, the weight of the males who feel either health or unhealthy have fairly similar weight. 

```{r  int-pairs-conditional-cdc, fig.show="hold", out.width="50%", fig.cap = "Barplot for variable pair (smoke100, age), and boxplot for variable pair (weight, gender) faceted by conditioning variable genhlth.", echo=TRUE}

show_assoc(d = cdcdata,
           x = "smoke100",
           y = "age",
           by = "genhlth")

show_assoc(d = cdcdata,
           x = "weight",
           y = "gender",
           by = "genhlth")
```


We also use linear layouts for displaying conditional association in the package. The function `plot_assoc_linear` is used for displaying a linear layout of the conditional association for variable pairs in the dataset. The association measures are calculated for every variable pair at each level of partitioning variable using `calc_assoc` function with conditioning variable as the `by` argument. 

The measures are then displayed using a dotplot (or a heatmap) where color of the dots (or each cell) is coded by the level of the partitioning variable and the variable pairs are ordered by absolute maximum value of association measure for each of the pair of variable. These displays are also efficient for discovering differences among the levels of partitioning variable in the data. In comparison to matrix layout, it is easier to omit less relevant pairs of variables in linear layouts by filtering the variables pairs having a higher value for association measures than a threshold.


Figure \@ref(fig:linear-cond-assoc) shows a linear display for conditional association measures with  the variable pairs having absoulte measure value greater than $0.1$  along the Y-axis, the value of association measure along X-axis and color of the points representing the level of the grouping variable. The linear layout becomes more useful over the matrix layout for conditional association display when the number of variables and number of levels of grouping variable are high.


```{r linear-cond-assoc, fig.width=5.5, fig.height=6.5, fig.align='center', fig.cap="Conditional Association plot using linear layout.The display has variable pairs on the Y-axis and the value of association measures on the X-axis. The points corresponding to every variable pair represents the value of association measure for different levels of the conditioning variable and the overall value of association measure.",echo=TRUE}

cond_assoc_cdc <- calc_assoc(d = cdcdata, 
                             by = "gender")
cond_assoc_cdc <- dplyr::filter(cond_assoc_cdc, abs(measure) > 0.1)
plot_assoc_linear(assoc = cond_assoc_cdc,
                  plot_type = "dotplot")
```



# Section 5: Discussion


We use multiple association measures in a single display for different variable pairs which serves as a comparison tool while exploring association in a dataset and assist in identifying unusual variable pairs. These multiple measures can be displayed in a scatterplot matrix similar to what @tukey1985computer proposed. They suggested that scatterplot matrix of the scagnostics measures, which are measures summarizing a scatterplot, can be used to identify unusual scatterplots or variable pairs. @wilkinson2005graph used this idea with their graph-theoretic scagnostic measures to highlight unusual scatterplots. Similarly, @kuhn2013applied have used this idea in a predictive modeling context. They have produced a scatterplot matrix of the measures between the response and continuous predictors such as Pearson's correlation coefficient, pseudo-$R^2$ from the locally weighted regression model, MIC and Spearman's rank correlation coefficient to explore the predictor importance during feature selection step. These displays show the importance of comparing multiple association measures at once for different variable pairs. 
